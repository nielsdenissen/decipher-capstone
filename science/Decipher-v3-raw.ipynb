{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run \"../code/translator.py\"\n",
    "#%run \"../code/validation.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain, permutations\n",
    "from collections import Counter\n",
    "import string\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "character_set = string.ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_word(self, original_word, character_set):\n",
    "    # Check if letters in character_set\n",
    "    valid_word = True\n",
    "    for letter in list(word):\n",
    "        if letter not in character_set:\n",
    "            valid_word = False\n",
    "\n",
    "    if valid_word:\n",
    "        return original_word.lower()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_encoded_words(self, msg_enc, character_set):\n",
    "    word_enc_list = set()\n",
    "\n",
    "    # Run through each unique encoded word and process it accordingly\n",
    "    for word_enc in set(re.findall(r\"[\\w']+\", msg_enc)):\n",
    "        processed_word = process_word(word_enc)\n",
    "        if processed_word is not None:\n",
    "            word_enc_list.add(processed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_word(original_word):\n",
    "    return original_word.lower()\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # Check if letters in character_set\n",
    "    valid_word = True\n",
    "    for letter in list(word):\n",
    "        if letter not in character_set:\n",
    "            valid_word = False\n",
    "            \n",
    "    return valid_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_key_for_word(word):\n",
    "    # Determine duplicates\n",
    "    duplicate_indices = []\n",
    "    for letter, letter_count in Counter(word).items():\n",
    "        if letter_count > 1:\n",
    "            indices = []\n",
    "            # Find indices of letter\n",
    "            from_index = 0\n",
    "            while len(indices) < letter_count:\n",
    "                new_index = word.index(letter, from_index)\n",
    "                indices.append(new_index)\n",
    "                from_index = new_index + 1\n",
    "\n",
    "            # Add to duplicate indices list\n",
    "            duplicate_indices.append(tuple(indices))\n",
    "    duplicate_indices = tuple(sorted(duplicate_indices))\n",
    "    \n",
    "    return (len(word),len(Counter(word)),duplicate_indices)\n",
    "\n",
    "def get_words_per_letter_count(language):\n",
    "    \"\"\"\n",
    "    Get the character frequency for a given language\n",
    "    \"\"\"\n",
    "    if language not in ['en', 'nl']:\n",
    "        raise NotImplementedError(\n",
    "            'Language {} not supported'.format(language))\n",
    "    \n",
    "    words = pickle.load(\n",
    "        open(\"../data/{}wiktionary.p\".format(language), \n",
    "             \"rb\"))\n",
    "    \n",
    "    word_dict = dict()\n",
    "    \n",
    "    for word in words:\n",
    "        processed_word = process_word(word)\n",
    "        if is_valid_word(processed_word):\n",
    "            try:\n",
    "                word_dict[get_key_for_word(processed_word)].append(processed_word)\n",
    "            except KeyError:\n",
    "                word_dict[get_key_for_word(processed_word)] = [processed_word]\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nl_words_per_count = get_words_per_letter_count('nl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test message letter frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " muc uw ffh cfwc vfruegcsf xk cf puspfh xo dllfw ffh vffcsf yfrpc fhbxaxxrcw kuwwegufh uw muc hxi hufc axlmxfhmf kddr ufcw uw hxi dlcusm vfcfr mdh hufcw cxeg \n"
     ]
    }
   ],
   "source": [
    "msg = '''\n",
    "this is a test message to see if everything is working properly\n",
    "we should be able to see if we can encrypt this one\n",
    "english is a hard language to comprehend in such a way as it is written now\n",
    "nobody really knows how many more lines we have to type before this damn thing\n",
    "finally translates to something useful\n",
    "let us just keep on trying\n",
    "'''\n",
    "msg = '''\n",
    "dit is een test berichtje om te kijken of alles een beetje werkt enzovoorts\n",
    "misschien is dit nog niet voldoende maar iets is nog altijd beter dan niets toch\n",
    "'''\n",
    "# msg = '''\n",
    "# dit is een test bericht om te kijken of het ontcijferen van een soortgelijk bericht\n",
    "# toepasselijk is in de nederland taal \n",
    "# contentmanagementsystemen frituurpannen ijdelheid familietrekjes betrekkelijk gezelligheid\n",
    "# '''\n",
    "#msg = '''contentmanagementsystemen'''\n",
    "\n",
    "# Remove linebreaks\n",
    "msg = msg.replace('\\n', ' ').replace('\\r', '')\n",
    "\n",
    "#Encode to something\n",
    "random_shuffle_characters = random.sample(character_set, len(character_set)) \n",
    "cipher_enc = create_cipher(character_set, random_shuffle_characters)\n",
    "msg_enc = encipher_text(msg, cipher_enc)\n",
    "\n",
    "#Print encoding\n",
    "print(msg_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' dit is een test berichtje om te kijken of alles een beetje werkt enzovoorts misschien is dit nog niet voldoende maar iets is nog altijd beter dan niets toch '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the actual cipher for decoding\n",
    "decipher_text(msg_enc, cipher_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find actual cipher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cycle through each group of words one by one, decipher them and see if it solves the puzzle. If not, try this with a different group first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_sentence(sentence, split_on=' '):\n",
    "    return re.findall(r\"[\\w']+\", sentence)\n",
    "\n",
    "word_enc_list = set(split_sentence(msg_enc))\n",
    "\n",
    "word_enc_possibility_dict = dict()\n",
    "\n",
    "# Run through each unique encoded word to find possibilities\n",
    "for word_enc in word_enc_list:\n",
    "    possibilities = nl_words_per_count[get_key_for_word(word_enc)]\n",
    "    word_enc_possibility_dict[word_enc] = possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_possible_words(word_enc, cipher={}):\n",
    "    possible_words = word_enc_possibility_dict[word_enc]\n",
    "    cipher_copy = cipher.copy()\n",
    "    \n",
    "    # Determine what to fill cipher with\n",
    "    # Replace this cipher with a negation of the already known values\n",
    "    # Those values cannot become the result of the cipher anymore\n",
    "    if len(cipher.values()) <= 0:\n",
    "        cipher_fill = '.'\n",
    "    else:\n",
    "        cipher_fill = '[^'+''.join(cipher.values())+']'\n",
    "    \n",
    "    # Fill cipher with missing keys\n",
    "    for c in list(character_set):\n",
    "        if c not in cipher_copy.keys():\n",
    "            cipher_copy[c] = cipher_fill\n",
    "    \n",
    "    regex_string = decipher_text(word_enc, cipher_copy)\n",
    "\n",
    "    regex = re.compile(regex_string)\n",
    "\n",
    "    # Filter out possibilities with current cipher keys\n",
    "    possible_words = list(filter(regex.search, possible_words))\n",
    "    return possible_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_trough_possible_words(word_enc, cipher={}):  \n",
    "    possible_words = get_possible_words(word_enc, cipher)\n",
    "    \n",
    "    for word_dec in possible_words:\n",
    "        cipher_for_this = create_cipher(word_enc, word_dec)\n",
    "        yield word_dec, {**cipher_for_this, **cipher}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_cipher_and_words_correct(ordered_list_words_enc, cipher_so_far={}):\n",
    "    if len(ordered_list_words_enc) <= 0:\n",
    "        return cipher_so_far, 0\n",
    "    else:\n",
    "        best_cipher=None\n",
    "        best_score=0\n",
    "        for possible_word_dec, cipher_used in run_trough_possible_words(ordered_list_words_enc[0], cipher_so_far):\n",
    "            new_cipher_so_far, num_correct = get_best_cipher_and_words_correct(ordered_list_words_enc[1:], cipher_used)\n",
    "            if num_correct+1 > best_score:\n",
    "                best_cipher = new_cipher_so_far\n",
    "                best_score = num_correct+1\n",
    "        \n",
    "        if best_score <= 0:\n",
    "            # We didn't find anything, ignore this word from now on\n",
    "            return get_best_cipher_and_words_correct(ordered_list_words_enc[1:], cipher_so_far)\n",
    "        else:\n",
    "            return best_cipher, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New plan, try bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_complexity(word_list, cipher):\n",
    "    complexity = 1\n",
    "    for w in word_list:\n",
    "        complexity *= len(get_possible_words(w,cipher))\n",
    "    \n",
    "    return complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_subset_words_per_letter(word_list, cipher_fixed, max_complexity=1e11, min_set_size=4):\n",
    "    # Determine the best order to walk through the letters (certain onces will be easier to workout)\n",
    "    # Now we choose the letters that occur in most words first\n",
    "    letter_scores = list()\n",
    "    for char in list(character_set):\n",
    "        word_set = [w for w in word_list if char in w]\n",
    "        if len(word_set) == 0:\n",
    "            avg_word_set_complexity = 0\n",
    "        else:\n",
    "            avg_word_set_complexity = min([calc_complexity([w],{}) for w in word_set])\n",
    "        score = len(word_set) - avg_word_set_complexity\n",
    "        letter_scores.append((char, score, word_set))\n",
    "    \n",
    "    letter_scores = sorted(letter_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for char, char_score, word_set in letter_scores:\n",
    "        complexity = calc_complexity(word_set, cipher_fixed)\n",
    "\n",
    "        # As long as the complexity is too high, reduce the set size\n",
    "        while complexity > max_complexity and len(word_set) >= min_set_size:\n",
    "            word_set = word_set[:-1]\n",
    "            complexity = calc_complexity(word_set, cipher_fixed)\n",
    "\n",
    "        # We only take sets of minimum x words\n",
    "        if len(word_set) >= min_set_size:\n",
    "            yield char, word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Start deciphering with minimum set of 10\n",
      "---- Start deciphering with minimum set of 9\n",
      "---- Start deciphering with minimum set of 8\n",
      "---- Start deciphering with minimum set of 7\n",
      "---- Start deciphering with minimum set of 6\n",
      "\t-- Letter f\n",
      "\t\tDecided for f:e\n",
      "\t\tNumber of correctly translated words: 6/6 (100%)\n",
      "\t-- Letter h\n",
      "\t\tDecided for h:n\n",
      "\t\tNumber of correctly translated words: 7/7 (100%)\n",
      "\t-- Letter c\n",
      "\t\tDecided for c:t\n",
      "\t\tNumber of correctly translated words: 6/6 (100%)\n",
      "\t-- Letter x\n",
      "\t\tDecided for x:o\n",
      "\t\tNumber of correctly translated words: 6/6 (100%)\n",
      "\t-- Letter w\n",
      "\t\tDecided for w:s\n",
      "\t\tNumber of correctly translated words: 7/7 (100%)\n",
      "\t-- Letter u\n",
      "\t\tDecided for u:i\n",
      "\t\tNumber of correctly translated words: 9/9 (100%)\n",
      "---- Start deciphering with minimum set of 5\n",
      "\t-- Letter r\n",
      "\t\tDecided for r:r\n",
      "\t\tNumber of correctly translated words: 5/5 (100%)\n",
      "---- Start deciphering with minimum set of 4\n",
      "\t-- Letter m\n",
      "\t\tDecided for m:d\n",
      "\t\tNumber of correctly translated words: 4/4 (100%)\n",
      "\t-- Letter s\n",
      "\t\tDecided for s:j\n",
      "\t\tNumber of correctly translated words: 4/4 (100%)\n",
      "\t-- Letter d\n",
      "\t\tDecided for d:a\n",
      "\t\tNumber of correctly translated words: 4/4 (100%)\n",
      "---- Start deciphering with minimum set of 3\n",
      "\t-- Letter l\n",
      "\t\tDecided for l:l\n",
      "\t\tNumber of correctly translated words: 3/3 (100%)\n",
      "\t-- Letter e\n",
      "\t\tDecided for e:c\n",
      "\t\tNumber of correctly translated words: 3/3 (100%)\n",
      "\t-- Letter g\n",
      "\t\tDecided for g:h\n",
      "\t\tNumber of correctly translated words: 3/3 (100%)\n",
      "\t-- Letter k\n",
      "\t\tDecided for k:m\n",
      "\t\tNumber of correctly translated words: 3/3 (100%)\n",
      "\t-- Letter v\n",
      "\t\tDecided for v:b\n",
      "\t\tNumber of correctly translated words: 3/3 (100%)\n",
      "---- Start deciphering with minimum set of 2\n",
      "\t-- Letter a\n",
      "\t\tDecided for a:v\n",
      "\t\tNumber of correctly translated words: 2/2 (100%)\n",
      "\t-- Letter p\n",
      "\t\tDecided for p:k\n",
      "\t\tNumber of correctly translated words: 2/2 (100%)\n",
      "---- Start deciphering with minimum set of 1\n",
      "\t-- Letter b\n",
      "\t\tDecided for b:z\n",
      "\t\tNumber of correctly translated words: 1/1 (100%)\n",
      "\t-- Letter o\n",
      "\t\tDecided for o:x\n",
      "\t\tNumber of correctly translated words: 1/1 (100%)\n",
      "\t-- Letter i\n",
      "\t\tDecided for i:u\n",
      "\t\tNumber of correctly translated words: 1/1 (100%)\n",
      "\t-- Letter y\n",
      "\t\tDecided for y:w\n",
      "\t\tNumber of correctly translated words: 1/1 (100%)\n",
      "\n",
      "Number of keys found: 21\n",
      "{'x': 'o', 'b': 'z', 'o': 'x', 'a': 'v', 'k': 'm', 'd': 'a', 'r': 'r', 'g': 'h', 'e': 'c', 'm': 'd', 'l': 'l', 'i': 'u', 'y': 'w', 'f': 'e', 'h': 'n', 'u': 'i', 'v': 'b', 'c': 't', 's': 'j', 'w': 's', 'p': 'k'}\n"
     ]
    }
   ],
   "source": [
    "# Sort the word_encoded list based on possibilities\n",
    "word_enc_list_ordered = sorted(word_enc_possibility_dict, key=lambda k: len(word_enc_possibility_dict[k]), reverse=False)\n",
    "\n",
    "cipher_already_fix = {}\n",
    "min_set_size = 10\n",
    "while min_set_size > 0:\n",
    "    print(\"---- Start deciphering with minimum set of {}\".format(min_set_size))\n",
    "    \n",
    "    gen_subsets = generate_subset_words_per_letter(word_enc_list_ordered, cipher_already_fix, max_complexity=1e12, min_set_size=min_set_size)\n",
    "    for used_letter, used_set in gen_subsets:\n",
    "        if used_letter not in cipher_already_fix.keys():\n",
    "            print(\"\\t-- Letter {}\".format(used_letter))\n",
    "            found_cipher, correct_words = get_best_cipher_and_words_correct(used_set,cipher_already_fix)\n",
    "            correctly_translated = correct_words/len(used_set)\n",
    "\n",
    "            try:\n",
    "                if found_cipher[used_letter] in cipher_already_fix.values():\n",
    "                    print(\"\\t\\t!!!! PROBLEM: this letter ({}) has been used to translate to already\".format(found_cipher[used_letter]))\n",
    "                else:\n",
    "                    cipher_already_fix[used_letter] = found_cipher[used_letter]\n",
    "\n",
    "                    print(\"\\t\\tDecided for {0}:{1}\".format(used_letter, found_cipher[used_letter]))\n",
    "                    print(\"\\t\\tNumber of correctly translated words: {0}/{1} ({2}%)\".format(correct_words, len(used_set), int(100*correctly_translated)))\n",
    "            except KeyError:\n",
    "                print(\"\\t\\tWe'd hoped to find this one, but couldnt: {}\".format(used_letter))\n",
    "\n",
    "    min_set_size -= 1\n",
    "    \n",
    "print()\n",
    "print(\"Number of keys found: {}\".format(len(cipher_already_fix)))\n",
    "print(cipher_already_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dit is een test berichtje om te kijken ox alles een beetje werkt enzovoorts misschien is dit nou niet voldoende maar iets is nou altijd beter dan niets toch \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' muc uw ffh cfwc vfruegcsf xk cf puspfh xo dllfw ffh vffcsf yfrpc fhbxaxxrcw kuwwegufh uw muc hxi hufc axlmxfhmf kddr ufcw uw hxi dlcusm vfcfr mdh hufcw cxeg '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_cipher_copy = cipher_already_fix.copy()\n",
    "\n",
    "# Figure out which values are missing\n",
    "\n",
    "# Fill cipher with missing keys\n",
    "for c in list(character_set):\n",
    "    if c not in found_cipher_copy.keys():\n",
    "        found_cipher_copy[c] = '_'\n",
    "\n",
    "print(decipher_text(msg_enc, found_cipher_copy))\n",
    "msg_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
